{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PubMed abstract들 중 소아과(ped), 내과(im), 외과(surg)와 관련된 것들을 모아 이를 분류하는 CNN 모델 시도\n",
    "- 미리 학습된 Word2Vec을 이용하지 않는 버젼\n",
    "- Text CNN을 이용하여 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_helpers import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, vocabulary, vocabulary_inv = load_data()\n",
    "\n",
    "# x.shape -> (2509, 815)\n",
    "# y.shape -> (2509, 3)\n",
    "# len(vocabulary) -> 19924\n",
    "# len(vocabulary_inv) -> 19924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2509, 815)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=1234)\n",
    "\n",
    "# X_train.shape -> (2007, 815)\n",
    "# y_train.shape -> (2007, 3)\n",
    "# X_test.shape -> (502, 815)\n",
    "# y_test.shape -> (502, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13025,  4625,  9916,  9219,  4388,  6189,  2956,  8938, 11734,\n",
       "        7110,  9182,  9880,  5403,  8400, 18178, 19784,  9916, 13865,\n",
       "        7269, 11743,  2191, 13891,  2192, 18237, 17552,  5152,  4391,\n",
       "       14646,  2956, 14471,  3508, 13106, 18178, 13891, 19784, 19735,\n",
       "       18178, 14768,  3383,  8560,  1097, 11882,  2897,  7005, 11438,\n",
       "       17815, 19580, 16670, 18355, 11783, 13106, 18178,  2867,  2287,\n",
       "       13106, 13869,  2191,  2208,  2192, 16568, 13167,  7240,  2956,\n",
       "       18355, 12759,  2208, 11783,  4008,  4579,  9916, 13891, 10130,\n",
       "       13167,  6202,   549, 14511,  4643,  2956, 14842,  2433,   549,\n",
       "        4391, 14646,   549,  8623, 14217,   549,  2956,  4210,  2191,\n",
       "       19174, 18742, 19239, 16523, 15258,  2192, 19580,  2930, 19174,\n",
       "       17325,  6297, 17373, 16009, 13106,  1110,   549,   789, 17819,\n",
       "       11439,   549,  2083, 15974, 19656, 15479,  2191,  1501,  1999,\n",
       "       15973,  2192, 13469,  9103,  2191,  1687,  1895,  2192, 13106,\n",
       "       15967, 19656,  8184,   549,  5152, 19735,  1558,  9916,  1097,\n",
       "       18178, 11457,  2191,  1805,  2090,  2192, 14513,  9916, 18178,\n",
       "        7269,  6237,  2191,  7086,  2192, 13106,  2194,  8531, 17336,\n",
       "        4716,   424,  9485, 18178,  6728, 13106, 14842,  2433, 19580,\n",
       "       16886, 18355, 18177, 15853,  9916,  1097,   549, 19735, 18178,\n",
       "       11457, 13106, 18316,  2191,  1778,  2192, 17212,  9916,  6535,\n",
       "       13779,  4388,  9103, 10035, 10539,  9916, 15906,   549,  2956,\n",
       "        2805,  9103,  9087,  6099, 18316,  8400, 13411,  2433,   549,\n",
       "        9967,  7269, 11734, 16716,  2191,  1895,  1325,  2192,   549,\n",
       "        6566,  2191,  1777,  2090,  2192,   549,  4708,  2271,  2191,\n",
       "        1638,   550,  2192,   549, 18576,  2191,  1325,  1777,  2192,\n",
       "         549, 18432,  2191,  1110,  1325, 13106, 15967,  2192,   549,\n",
       "        2956, 13411,  2191,   821,  1777,  2192,  2471,   549,  1156,\n",
       "        1325,  9087,  6099, 18316,  8400, 15219, 16341, 15967, 19656,\n",
       "        9375, 16390,  2191,  2136,  1777,  2192, 19735,  8180, 14646,\n",
       "        8400,  4892,  4388,   549,  4218, 11087, 16390, 19735, 14646,\n",
       "        8400, 15906,  2191,  1623,  1110,  2192,  2956,  2528,  2191,\n",
       "        1460,  1895,  2192,  9519,   549, 16388, 19735, 12781, 18487,\n",
       "       19580,  9369,  8400, 18250, 19745,   704, 19869, 13106, 11734,\n",
       "       16480,  8942,  8467, 16948, 13920, 14212, 18355,  4622,  4892,\n",
       "        2434,  9916, 18178, 12679,  1638, 19869,   549,  9967, 15579,\n",
       "        9509,   549,  4626, 16798,   549, 13289, 16043, 13471,   549,\n",
       "         745,  2090, 13106,  2773, 15967,   549,  9967,  1112,   702,\n",
       "       13106, 19763,  2956,  1110,  1777, 13106, 11797,  2191, 13543,\n",
       "         550,   566,  2192,   549, 15851,  5881, 19788, 13695, 18316,\n",
       "       10955, 11456,  7377,  8169,  4209, 13431,  3435, 19774,  2191,\n",
       "        2069,  1638,  2192, 13289, 12212,  4278, 18426, 13911,  3325,\n",
       "        2194, 16004, 13106, 19774,  2191,  1863,  1638,  2192,  3435,\n",
       "       11037, 12195,   549, 19735, 13186,  9916,  8313, 15857, 17672,\n",
       "        8170,  3435, 11037, 19632,  5298, 19673, 16388, 19735,  8180,\n",
       "       14646,  8400, 14842,  2433,  9916, 13891, 10601,  9906,   549,\n",
       "        8668, 15759,  9916, 18487,  9916, 12781, 16971, 17880, 13106,\n",
       "        4210,  3242, 14728,   549,  2956, 18206, 10601, 11161, 18355,\n",
       "        3762, 17637,  3508, 13106, 13891, 15015,  9916, 18178, 12515,\n",
       "        8623,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,  2190,\n",
       "        2190,  2190,  2190,  2190,  2190])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD/>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_inv[2190]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = x.shape[1] # 815\n",
    "vocabulary_size = len(vocabulary_inv) # 19924\n",
    "embedding_dim = 200\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 64\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model design\n",
    "Keras에는 두 가지의 모델 생성 방법이 있습니다.\n",
    "\n",
    "1. Sequential Models\n",
    "2. Functional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential model API**는 상당히 쉽게 딥러닝 모델을 생성하는 인터페이스를 제공하지만 한 방향성으로만 모델을 생성시킨다는 단점이 있습니다. 따라서 다음의 경우에는 Sequential model API로 모델을 생성하기가 어렵습니다.\n",
    "\n",
    "1. 다중의 입력 소스를 만들 경우\n",
    "2. 다중의 출력 층을 만들 경우\n",
    "3. 층을 여러 방향으로 공유하는 경우 등."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 방법은 **Functional model API**를 이용하는 것입니다. 이 방법은 좀 더 유연하게 딥러닝 모델을 디자인할 수 있게 합니다.\n",
    "만드는 것은 전혀 어렵지 않습니다. `keras.models.Model`을 활용하여 생성할 수 있으며 **Input**과 **Output**만 잘 정의해주면 됩니다.\n",
    "\n",
    "**Functional model API**에 대한 자세한 가이드는 Keras 공식 문서 (https://keras.io/getting-started/functional-api-guide/)를 참고하시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 **Functional model API**로 모델을 생성한 경우입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
    "embedding = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=sequence_length)(inputs)\n",
    "reshape = Reshape((sequence_length, embedding_dim, 1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=y_train.shape[1], activation='softmax')(dropout)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 815), dtype=int32)\n",
      "Tensor(\"embedding_1/embedding_lookup/Identity:0\", shape=(?, 815, 200), dtype=float32)\n",
      "Tensor(\"reshape_1/Reshape:0\", shape=(?, 815, 200, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs)\n",
    "print(embedding)\n",
    "print(reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 815)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 815, 200)     3984800     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 815, 200, 1)  0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 813, 1, 64)   38464       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 812, 1, 64)   51264       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 811, 1, 64)   64064       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 64)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 192)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 192)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            579         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,139,171\n",
      "Trainable params: 4,139,171\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 학습 시 성능이 좋아지면, 그 때의 가중치를 저장하는 코드\n",
    "# # 용량이 크므로 개인 컴퓨터에서 저장 공간을 어느 정도 확보한 후에 실행하는 것이 좋음\n",
    "# checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Model...\n",
      "Train on 2007 samples, validate on 502 samples\n",
      "Epoch 1/20\n",
      "2007/2007 [==============================] - 68s 34ms/step - loss: 0.5483 - acc: 0.7225 - val_loss: 0.3335 - val_acc: 0.8904\n",
      "Epoch 2/20\n",
      "2007/2007 [==============================] - 63s 32ms/step - loss: 0.2376 - acc: 0.9146 - val_loss: 0.2364 - val_acc: 0.9064\n",
      "Epoch 3/20\n",
      "2007/2007 [==============================] - 64s 32ms/step - loss: 0.1638 - acc: 0.9432 - val_loss: 0.2175 - val_acc: 0.9183\n",
      "Epoch 4/20\n",
      " 768/2007 [==========>...................] - ETA: 36s - loss: 0.1160 - acc: 0.9601"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9ebf08e0dd7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Check point가 없을 때,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# starts training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Traning Model...\")\n",
    "\n",
    "# # Check point가 있을 때,\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[checkpoint], validation_data=(X_test, y_test))  # starts training\n",
    "\n",
    "# Check point가 없을 때,\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0\n",
      "organ donation after circulatory death \\( dcd \\) has experienced a revival worldwide over the past 20 years , and is now widely practiced for kidney transplantation some previous concerns about these organs such as the high incidence of delayed graft function have been alleviated through evidence from adult studies there are now a number of large adult cohorts reporting favorable 5 year outcomes for dcd kidney transplants , comparable to kidneys donated after brain death \\( dbd \\) this has resulted in a marked increase in the use of dcd kidneys for adult recipients in some countries and an increase in the overall number of kidney transplants in contrast , the uptake of dcd kidneys for pediatric recipients is still low and concerns still exist over the longer term outcomes of dcd organs in view of the data from adult practice and the poor outcomes for children who stay on dialysis , dcd kidney transplantation should be offered as an option for children on the kidney transplant waiting list\n",
      "\n",
      "\n",
      "0\t0\n",
      "organ donation after circulatory death \\( dcd \\) has experienced a revival worldwide over the past 20 years , and is now widely practiced for kidney transplantation some previous concerns about these organs such as the high incidence of delayed graft function have been alleviated through evidence from adult studies there are now a number of large adult cohorts reporting favorable 5 year outcomes for dcd kidney transplants , comparable to kidneys donated after brain death \\( dbd \\) this has resulted in a marked increase in the use of dcd kidneys for adult recipients in some countries and an increase in the overall number of kidney transplants in contrast , the uptake of dcd kidneys for pediatric recipients is still low and concerns still exist over the longer term outcomes of dcd organs in view of the data from adult practice and the poor outcomes for children who stay on dialysis , dcd kidney transplantation should be offered as an option for children on the kidney transplant waiting list\n",
      "\n",
      "\n",
      "1\t1\n",
      "background simulation training may improve proficiency at and reduce complications from central venous catheter \\( cvc \\) placement , but the scope of simulation 's effect remains unclear this randomized controlled trial evaluated the effects of a pragmatic cvc simulation program on procedural protocol adherence , technical skill , and patient outcomes methods internal medicine interns were randomized to standard training for cvc insertion or standard training plus simulation based mastery training standard training involved a lecture , a video based online module , and instruction by the supervising physician during actual cvc insertions intervention group subjects additionally underwent supervised training on a venous access simulator until they demonstrated procedural competence raters evaluated interns' performance during internal jugular cvc placement on actual patients in the medical intensive care unit generalized estimating equations were used to account for outcome clustering within trainees results we observed 52 interns placing 87 cvcs simulation trained interns exhibited better adherence to prescribed procedural technique than interns who received only standard training \\( p 0 024 \\) there were no significant differences detected in first attempt or overall cannulation success rates , mean needle passes , global assessment scores , or complication rates conclusions simulation training added to standard training improved protocol adherence during cvc insertion by novice practitioners this study may have been too small to detect meaningful differences in venous cannulation proficiency and other clinical outcomes , highlighting the difficulty of patient centered simulation research in settings where poor outcomes are rare for high performing systems , where protocol deviations may provide an important proxy for rare procedural complications , simulation may improve cvc insertion quality and safety\n",
      "\n",
      "\n",
      "0\t0\n",
      "purpose thoracoscopic lobectomy in infants requires advanced minimally invasive skills simulation based education has the potential to improve complex procedural skills without exposing the patient to undue risks the study purposes were \\( 1 \\) to create a size appropriate infant lobectomy simulator and \\( 2 \\) to evaluate validity evidence to support or refute its use in surgical education materials and methods in this institutional review board exempt study , a size appropriate rib cage for a 3 month old infant was created fetal bovine tissue completed the simulator thirty three participants performed the simulated thoracoscopic lobectomy participants completed a self report , 26 item instrument consisting of 25 4 point rating scales \\( from 1 not realistic to 4 highly realistic \\) and a one 4 point global rating scale validity evidence relevant to test content and response processes was evaluated using the many facet rasch model , and evidence of internal structure \\( inter item consistency \\) was estimated using cronbach 's alpha results experienced surgeons \\( observed average 3 6 \\) had slightly higher overall rating than novice surgeons \\( observed average 3 4 , p 001 \\) the highest combined observed averages were for the domain physical attributes \\( 3 7 \\) , whereas the lowest ratings were for the domains realism of experience and ability to perform tasks \\( 3 4 \\) the global rating was 2 9 , consistent with 'this simulator can be considered for use in infant lobectomy training , but could be improved slightly ' inter item consistency for items used to evaluate the simulator 's quality was high \\( 0 90 \\) conclusions with ratings consistent with high physical attributes and realism , we successfully created an infant lobectomy simulator , and preliminary evidence relevant to test content , response processes , and internal structure was supported participants rated the model as realistic , relevant to clinical practice , and valuable as a learning tool minor improvements were suggested prior to its full implementation as an educational and testing tool\n",
      "\n",
      "\n",
      "0\t0\n",
      "introduction despite appendicitis being one of the most common surgical emergencies in the pediatric population , there is still a great deal of debate among pediatric surgeons regarding the workup and treatment materials and methods in an interactive web symposium consisting of 130 pediatric surgeons from various regions of the world , questions about diagnosis and management of appendicitis were displayed on the screen the audience was asked to respond to the poll questions the questions asked to the participants pertained to an example case of a 12 year old boy presenting to the emergency department with the classic history and exam for appendicitis results the total number of respondents varied between 30 and 37 , giving response rates of 23 28 sixty six percent of respondents would not order imaging thirty one percent said that they would order ultrasound no participant would order a computed tomography scan , whereas 5 would order some other form ninety five percent of respondents said that they would treat the patient operatively the majority \\( 89 \\) of the participants felt comfortable waiting until morning to operate on the patient if the patient arrived at 11 p m fifty seven percent stated that they would use a three port laparoscopic approach , and 38 would use a single port , whereas 5 would use an open surgical approach the majority \\( 34 \\) reported being able to visualize the appendix as the greatest benefit to using laparoscopy fifty seven percent would give the patient one additional dose of antibiotics and then discharge him 24 hours later following treatment for acute , nonperforated appendicitis twenty percent of respondents would give no further antibiotics and would discharge the patient from the recovery room or soon after sixteen percent would not give any additional antibiotics and would discharge him 24 hours postoperatively , whereas 6 would give one additional dose of antibiotics and discharge him soon after conclusions the use of virtual broadcasts affords a unique opportunity to surgeons around the world to share and learn from each other\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(len(X_test))\n",
    "    x_test = X_test[idx].reshape(1,X_test.shape[1])\n",
    "    y_label = y_test[idx][0]\n",
    "    y_pred = model.predict(x_test)[0][0]\n",
    "    sent = \" \".join([vocabulary_inv[x] for x in x_test[0].tolist() if x != 0])\n",
    "    print(\"%.0f\\t%d\\n%s\" % (y_pred, y_label, sent.replace('<PAD/>', '').strip()))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
